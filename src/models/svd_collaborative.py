"""
Layer 2: Matrix Factorization via Singular Value Decomposition (SVD).
This module leverages the Surprise library to perform latent factor analysis.
It serves as a re-ranking engine that refines candidates generated by the 
Content-Based layer using collaborative signals.
"""

# Execution Script:
# python -m src.models.svd_collaborative

from surprise import SVD, Dataset, Reader #type: ignore
import pandas as pd #type: ignore
from src.data.loader import load_ratings_by_fold, load_movies_df
from src.models.content_based import ContentBasedRecommender
from config import SVD_N_FACTORS, SVD_N_EPOCHS, SVD_LR, SVD_REG
import time

class CollaborativeFilteringSVD:
    """
    Model-based Collaborative Filtering implementation using SVD.
    The model factorizes the user-item interaction matrix into lower-dimensional 
    user and item embeddings (latent factors) to predict unobserved ratings.
    """
    
    def __init__(self, n_factors=50, n_epochs=20, lr=0.005, reg=0.02):
        """
        Initialize the SVD regressor with specific hyperparameters for SGD optimization.
        
        Args:
            n_factors: Dimensionality of the latent space (K factors).
            n_epochs: Iterations for Stochastic Gradient Descent (SGD).
            lr: Global learning rate for parameter updates.
            reg: Regularization term (lambda) to prevent overfitting by penalizing large magnitudes.
        """
        # Initialize the SVD algorithm from Surprise
        self.model = SVD(
            n_factors=n_factors,
            n_epochs=n_epochs,
            lr_all=lr,
            reg_all=reg,
            verbose=True
        )
        self.is_trained = False
    
    def train(self, train_data):
        """
        Map raw interaction data into a Surprise-compatible format and perform factorization.
        
        Args:
            train_data: Input DataFrame containing [user_id, item_id, rating].
        """
        # Define the rating scale for the Reader object
        reader = Reader(rating_scale=(1, 5))
        
        # Matrix restructuring: Ensuring the interaction matrix follows the [user, item, rating] schema
        if 'item_id' in train_data.columns:
            df = train_data[['user_id', 'item_id', 'rating']].copy()
        else:
            df = train_data[['user_id', 'movie_id', 'rating']].copy()
            df.columns = ['user_id', 'item_id', 'rating']
        
        # Transformation of DataFrame into a specialized Surprise Trainset object
        dataset = Dataset.load_from_df(df, reader)
        trainset = dataset.build_full_trainset()
        
        # Execute matrix factorization via SGD
        self.model.fit(trainset)
        self.is_trained = True
        print(f"SVD model successfully converged on {trainset.n_users} users and {trainset.n_items} items")
    
    def predict(self, user_id, item_id):
        """
        Estimate the rating score for a specific user-item pair using the dot product
         of learned user and item latent vectors.
        
        Returns:
            float: Scalar value representing the estimated rating (clamped to scale).
        """
        if not self.is_trained:
            raise ValueError("Inference failed: SVD model must be trained prior to prediction.")
        
        # Compute prediction using the learned pu and qi vectors
        prediction = self.model.predict(user_id, item_id)
        return prediction.est
    
    def recommend(self, user_id, candidate_items, top_k=50):
        """
        Second-stage Re-ranking: Sorts a subset of candidate items from Layer 1 
        based on the collaborative filtering preference scores.
        
        Args:
            user_id: Target user for recommendation.
            candidate_items: Candidate pool generated by the Content-Based layer.
            top_k: Number of highest-ranked items to retrieve.
        
        Returns:
            list: Sorted list of movie IDs representing the top collaborative matches.
        """
        if not self.is_trained:
            raise ValueError("Recommendation failed: Model state is not trained.")
        
        # Batch scoring of candidates
        predictions = []
        for item_id in candidate_items:
            pred_rating = self.predict(user_id, item_id)
            predictions.append((item_id, pred_rating))
        
        # Sort candidates in descending order of predicted preference
        predictions.sort(key=lambda x: x[1], reverse=True)
        return [item_id for item_id, _ in predictions[:top_k]]
    
    def get_user_factors(self, user_id):
        """
        Expose user latent factors (User Embeddings).
        Useful for downstream analysis like user clustering or similarity search.
        """
        if not self.is_trained:
            raise ValueError("Access denied: Model factors are only available after training.")
        
        try:
            # Map external raw ID to internal surprise index
            inner_uid = self.model.trainset.to_inner_uid(user_id)
            return self.model.pu[inner_uid]
        except ValueError:
            return None
    
    def get_item_factors(self, item_id):
        """
        Expose item latent factors (Item Embeddings).
        Facilitates item-to-item similarity analysis in the latent space.
        """
        if not self.is_trained:
            raise ValueError("Access denied: Model factors are only available after training.")
        
        try:
            # Map external raw ID to internal surprise index
            inner_iid = self.model.trainset.to_inner_iid(item_id)
            return self.model.qi[inner_iid]
        except ValueError:
            return None

# --- Main Pipeline Execution ---
if __name__ == "__main__":
    # Dataset Acquisition
    ratings_df = load_ratings_by_fold() 
    movies_df = load_movies_df()
    
    # Layer 1: Content-Based Filtering (Candidate Generation)
    content_model = ContentBasedRecommender(movies_df, ratings_df)
    user_id = 1
    candidates = content_model.recommend(user_id, top_k=100)
    print(f"Initial Candidates from Content-Based Layer: {len(candidates)}")
    
    # Layer 2: SVD Training and Re-ranking
    svd_model = CollaborativeFilteringSVD(
        n_factors=SVD_N_FACTORS,
        n_epochs=SVD_N_EPOCHS,
        lr=SVD_LR,
        reg=SVD_REG
    )
    
    start_time = time.time()
    svd_model.train(ratings_df)
    train_time = time.time()
    print(f"SVD Optimization Latency: {train_time - start_time:.4f} seconds")
    
    # Execute Re-ranking on candidates
    reranked = svd_model.recommend(user_id, candidates, top_k=50)
    print(f"Final Re-ranked Results: {len(reranked)}")
    
    # Statistical Summary of Top-10 Predictions
    print("\n--- Top 10 Predictions Analysis ---")
    for movie_id in reranked[:10]:
        pred = svd_model.predict(user_id, movie_id)
        print(f"Movie ID {movie_id:4}: Predicted Preference Score = {pred:.2f}")